#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä»£ç åˆ†æå™¨ - éœ²å°¼è¥¿äºšçš„ä»£ç ç†è§£èƒ½åŠ›
æ”¯æŒPythonã€Javaã€JavaScriptã€C++ç­‰å¤šç§ç¼–ç¨‹è¯­è¨€çš„æ™ºèƒ½åˆ†æ
"""

import os
import ast
import re
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from pathlib import Path

@dataclass
class CodeAnalysisResult:
    """ä»£ç åˆ†æç»“æœ"""
    language: str
    file_name: str
    content: str
    structure: Dict[str, Any]
    metrics: Dict[str, Any]
    summary: str
    analysis: str
    success: bool
    error: Optional[str] = None

class PythonCodeAnalyzer:
    """Pythonä»£ç åˆ†æå™¨ï¼ˆä½¿ç”¨ASTï¼‰"""
    
    def __init__(self):
        self.name = "Pythonä»£ç åˆ†æå™¨"
    
    def analyze(self, file_path: str) -> CodeAnalysisResult:
        """åˆ†æPythonä»£ç """
        try:
            print(f"ğŸ å¼€å§‹åˆ†æPythonä»£ç : {file_path}")
            
            # è¯»å–ä»£ç å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                code_content = f.read()
            
            # è§£æAST
            try:
                tree = ast.parse(code_content)
            except SyntaxError as e:
                return CodeAnalysisResult(
                    language="Python",
                    file_name=os.path.basename(file_path),
                    content=code_content,
                    structure={},
                    metrics={},
                    summary=f"è¯­æ³•é”™è¯¯: {str(e)}",
                    analysis="",
                    success=False,
                    error=f"Pythonè¯­æ³•é”™è¯¯: {str(e)}"
                )
            
            # æå–ä»£ç ç»“æ„
            structure = self._extract_structure(tree, code_content)
            
            # è®¡ç®—ä»£ç åº¦é‡
            metrics = self._calculate_metrics(tree, code_content)
            
            # ç”Ÿæˆæ‘˜è¦å’Œåˆ†æ
            summary = self._generate_summary(structure, metrics)
            analysis = self._generate_analysis(structure, metrics)
            
            return CodeAnalysisResult(
                language="Python",
                file_name=os.path.basename(file_path),
                content=code_content,
                structure=structure,
                metrics=metrics,
                summary=summary,
                analysis=analysis,
                success=True
            )
            
        except Exception as e:
            print(f"âŒ Pythonä»£ç åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return CodeAnalysisResult(
                language="Python",
                file_name=os.path.basename(file_path),
                content="",
                structure={},
                metrics={},
                summary="",
                analysis="",
                success=False,
                error=str(e)
            )
    
    def _extract_structure(self, tree: ast.AST, code: str) -> Dict[str, Any]:
        """æå–ä»£ç ç»“æ„"""
        structure = {
            "imports": [],
            "classes": [],
            "functions": [],
            "variables": [],
            "decorators": []
        }
        
        for node in ast.walk(tree):
            # å¯¼å…¥è¯­å¥
            if isinstance(node, ast.Import):
                for alias in node.names:
                    structure["imports"].append({
                        "type": "import",
                        "name": alias.name,
                        "alias": alias.asname
                    })
            elif isinstance(node, ast.ImportFrom):
                module = node.module or ""
                for alias in node.names:
                    structure["imports"].append({
                        "type": "from",
                        "module": module,
                        "name": alias.name,
                        "alias": alias.asname
                    })
            
            # ç±»å®šä¹‰
            elif isinstance(node, ast.ClassDef):
                bases = [self._get_name(base) for base in node.bases]
                methods = []
                class_vars = []
                
                for item in node.body:
                    if isinstance(item, ast.FunctionDef):
                        methods.append({
                            "name": item.name,
                            "args": [arg.arg for arg in item.args.args],
                            "decorators": [self._get_name(d) for d in item.decorator_list],
                            "is_async": isinstance(item, ast.AsyncFunctionDef),
                            "docstring": ast.get_docstring(item)
                        })
                    elif isinstance(item, ast.Assign):
                        for target in item.targets:
                            if isinstance(target, ast.Name):
                                class_vars.append(target.id)
                
                structure["classes"].append({
                    "name": node.name,
                    "bases": bases,
                    "methods": methods,
                    "class_variables": class_vars,
                    "decorators": [self._get_name(d) for d in node.decorator_list],
                    "docstring": ast.get_docstring(node)
                })
            
            # å‡½æ•°å®šä¹‰ï¼ˆé¡¶å±‚ï¼‰
            elif isinstance(node, ast.FunctionDef) and isinstance(node, ast.Module):
                # åªç»Ÿè®¡æ¨¡å—çº§åˆ«çš„å‡½æ•°
                continue
        
        # ç»Ÿè®¡é¡¶å±‚å‡½æ•°ï¼ˆä¸åœ¨ç±»ä¸­çš„ï¼‰
        for node in tree.body:
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                structure["functions"].append({
                    "name": node.name,
                    "args": [arg.arg for arg in node.args.args],
                    "decorators": [self._get_name(d) for d in node.decorator_list],
                    "is_async": isinstance(node, ast.AsyncFunctionDef),
                    "docstring": ast.get_docstring(node)
                })
            # å…¨å±€å˜é‡
            elif isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name):
                        structure["variables"].append(target.id)
        
        return structure
    
    def _get_name(self, node):
        """è·å–èŠ‚ç‚¹åç§°"""
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Attribute):
            return f"{self._get_name(node.value)}.{node.attr}"
        elif isinstance(node, ast.Call):
            return self._get_name(node.func)
        else:
            return str(node)
    
    def _calculate_metrics(self, tree: ast.AST, code: str) -> Dict[str, Any]:
        """è®¡ç®—ä»£ç åº¦é‡"""
        lines = code.split('\n')
        
        # ç»Ÿè®¡å„ç§èŠ‚ç‚¹
        node_counts = {
            "total_lines": len(lines),
            "code_lines": len([line for line in lines if line.strip() and not line.strip().startswith('#')]),
            "comment_lines": len([line for line in lines if line.strip().startswith('#')]),
            "blank_lines": len([line for line in lines if not line.strip()]),
            "classes": 0,
            "functions": 0,
            "methods": 0,
            "imports": 0,
            "if_statements": 0,
            "for_loops": 0,
            "while_loops": 0,
            "try_blocks": 0,
            "with_statements": 0
        }
        
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                node_counts["classes"] += 1
            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                node_counts["functions"] += 1
            elif isinstance(node, (ast.Import, ast.ImportFrom)):
                node_counts["imports"] += 1
            elif isinstance(node, ast.If):
                node_counts["if_statements"] += 1
            elif isinstance(node, ast.For):
                node_counts["for_loops"] += 1
            elif isinstance(node, ast.While):
                node_counts["while_loops"] += 1
            elif isinstance(node, ast.Try):
                node_counts["try_blocks"] += 1
            elif isinstance(node, ast.With):
                node_counts["with_statements"] += 1
        
        # è®¡ç®—å¤æ‚åº¦
        node_counts["complexity_score"] = (
            node_counts["if_statements"] + 
            node_counts["for_loops"] + 
            node_counts["while_loops"] + 
            node_counts["try_blocks"]
        )
        
        return node_counts
    
    def _generate_summary(self, structure: Dict, metrics: Dict) -> str:
        """ç”Ÿæˆä»£ç æ‘˜è¦"""
        summary_parts = []
        
        summary_parts.append(f"ğŸ“Š ä»£ç è¡Œæ•°: {metrics['total_lines']} è¡Œ")
        summary_parts.append(f"  - æœ‰æ•ˆä»£ç : {metrics['code_lines']} è¡Œ")
        summary_parts.append(f"  - æ³¨é‡Š: {metrics['comment_lines']} è¡Œ")
        summary_parts.append(f"  - ç©ºè¡Œ: {metrics['blank_lines']} è¡Œ")
        
        if structure["imports"]:
            summary_parts.append(f"ğŸ“¦ å¯¼å…¥æ¨¡å—: {len(structure['imports'])} ä¸ª")
        
        if structure["classes"]:
            total_methods = sum(len(cls["methods"]) for cls in structure["classes"])
            summary_parts.append(f"ğŸ—ï¸ ç±»å®šä¹‰: {len(structure['classes'])} ä¸ª (å…± {total_methods} ä¸ªæ–¹æ³•)")
        
        if structure["functions"]:
            summary_parts.append(f"âš™ï¸ å‡½æ•°å®šä¹‰: {len(structure['functions'])} ä¸ª")
        
        if metrics.get("complexity_score", 0) > 0:
            complexity_level = "ä½"
            if metrics["complexity_score"] > 50:
                complexity_level = "é«˜"
            elif metrics["complexity_score"] > 20:
                complexity_level = "ä¸­"
            summary_parts.append(f"ğŸ“ˆ ä»£ç å¤æ‚åº¦: {complexity_level} ({metrics['complexity_score']})")
        
        return "\n".join(summary_parts)
    
    def _generate_analysis(self, structure: Dict, metrics: Dict) -> str:
        """ç”Ÿæˆä»£ç åˆ†æ"""
        analysis_parts = []
        
        # ä»£ç ç»„ç»‡åˆ†æ
        if structure["classes"]:
            analysis_parts.append("ğŸ—ï¸ é¢å‘å¯¹è±¡è®¾è®¡ï¼šä½¿ç”¨äº†ç±»ç»“æ„")
            
            # åˆ†æç±»çš„ç‰¹ç‚¹
            class_features = []
            for cls in structure["classes"]:
                if cls["bases"]:
                    class_features.append(f"ç»§æ‰¿å…³ç³»")
                    break
            
            for cls in structure["classes"]:
                for method in cls["methods"]:
                    if method["decorators"]:
                        class_features.append("ä½¿ç”¨è£…é¥°å™¨")
                        break
                if class_features:
                    break
            
            if class_features:
                analysis_parts.append(f"  ç‰¹ç‚¹: {', '.join(class_features)}")
        
        # å¯¼å…¥åˆ†æ
        if structure["imports"]:
            import_modules = set()
            for imp in structure["imports"]:
                if imp["type"] == "import":
                    import_modules.add(imp["name"].split('.')[0])
                else:
                    import_modules.add(imp["module"].split('.')[0] if imp["module"] else "")
            
            common_libs = {"os", "sys", "json", "re", "typing", "pathlib"}
            web_libs = {"flask", "django", "fastapi", "requests", "aiohttp"}
            data_libs = {"pandas", "numpy", "matplotlib", "sklearn", "tensorflow", "torch"}
            
            detected_libs = []
            if import_modules & web_libs:
                detected_libs.append("Webæ¡†æ¶")
            if import_modules & data_libs:
                detected_libs.append("æ•°æ®åˆ†æ/æœºå™¨å­¦ä¹ ")
            if import_modules & common_libs:
                detected_libs.append("æ ‡å‡†åº“")
            
            if detected_libs:
                analysis_parts.append(f"ğŸ“¦ ä¾èµ–ç±»å‹: {', '.join(detected_libs)}")
        
        # ä»£ç é£æ ¼åˆ†æ
        if structure["functions"] or structure["classes"]:
            has_docstrings = False
            
            for func in structure["functions"]:
                if func.get("docstring"):
                    has_docstrings = True
                    break
            
            if not has_docstrings:
                for cls in structure["classes"]:
                    if cls.get("docstring"):
                        has_docstrings = True
                        break
            
            if has_docstrings:
                analysis_parts.append("ğŸ“ åŒ…å«æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œä»£ç è§„èŒƒæ€§è‰¯å¥½")
        
        # å¼‚æ­¥ç¼–ç¨‹
        async_count = len([f for f in structure["functions"] if f.get("is_async")])
        for cls in structure["classes"]:
            async_count += len([m for m in cls["methods"] if m.get("is_async")])
        
        if async_count > 0:
            analysis_parts.append(f"âš¡ ä½¿ç”¨å¼‚æ­¥ç¼–ç¨‹ ({async_count} ä¸ªasyncå‡½æ•°/æ–¹æ³•)")
        
        # é”™è¯¯å¤„ç†
        if metrics.get("try_blocks", 0) > 0:
            analysis_parts.append(f"ğŸ›¡ï¸ åŒ…å«å¼‚å¸¸å¤„ç† ({metrics['try_blocks']} ä¸ªtryå—)")
        
        return "\n".join(analysis_parts) if analysis_parts else "ğŸ“„ æ ‡å‡†Pythonä»£ç "

class GeneralCodeAnalyzer:
    """é€šç”¨ä»£ç åˆ†æå™¨ï¼ˆæ”¯æŒJavaã€JavaScriptã€C++ç­‰ï¼‰"""
    
    def __init__(self):
        self.name = "é€šç”¨ä»£ç åˆ†æå™¨"
        
        # è¯­è¨€ç‰¹å¾æ¨¡å¼
        self.language_patterns = {
            "java": {
                "extensions": [".java"],
                "class_pattern": r'class\s+(\w+)',
                "method_pattern": r'(public|private|protected)?\s*\w+\s+(\w+)\s*\(',
                "import_pattern": r'import\s+([\w.]+);'
            },
            "javascript": {
                "extensions": [".js", ".jsx", ".ts", ".tsx"],
                "class_pattern": r'class\s+(\w+)',
                "function_pattern": r'function\s+(\w+)\s*\(|const\s+(\w+)\s*=\s*\(',
                "import_pattern": r'import\s+.*from\s+[\'"](.+)[\'"]'
            },
            "cpp": {
                "extensions": [".cpp", ".cc", ".cxx", ".h", ".hpp"],
                "class_pattern": r'class\s+(\w+)',
                "function_pattern": r'\w+\s+(\w+)\s*\(',
                "include_pattern": r'#include\s*[<"](.+)[>"]'
            },
            "c": {
                "extensions": [".c", ".h"],
                "function_pattern": r'\w+\s+(\w+)\s*\(',
                "include_pattern": r'#include\s*[<"](.+)[>"]'
            },
            "go": {
                "extensions": [".go"],
                "function_pattern": r'func\s+(\w+)\s*\(',
                "import_pattern": r'import\s+"(.+)"'
            },
            "rust": {
                "extensions": [".rs"],
                "function_pattern": r'fn\s+(\w+)\s*\(',
                "struct_pattern": r'struct\s+(\w+)'
            }
        }
    
    def detect_language(self, file_path: str) -> str:
        """æ£€æµ‹ç¼–ç¨‹è¯­è¨€"""
        ext = os.path.splitext(file_path)[1].lower()
        
        for lang, config in self.language_patterns.items():
            if ext in config.get("extensions", []):
                return lang
        
        return "unknown"
    
    def analyze(self, file_path: str) -> CodeAnalysisResult:
        """åˆ†æä»£ç æ–‡ä»¶"""
        try:
            language = self.detect_language(file_path)
            
            if language == "unknown":
                return CodeAnalysisResult(
                    language="Unknown",
                    file_name=os.path.basename(file_path),
                    content="",
                    structure={},
                    metrics={},
                    summary="ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹",
                    analysis="",
                    success=False,
                    error=f"æ— æ³•è¯†åˆ«æ–‡ä»¶ç±»å‹: {os.path.splitext(file_path)[1]}"
                )
            
            print(f"ğŸ’» å¼€å§‹åˆ†æ{language.upper()}ä»£ç : {file_path}")
            
            # è¯»å–ä»£ç å†…å®¹
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                code_content = f.read()
            
            # æå–ä»£ç ç»“æ„
            structure = self._extract_structure(code_content, language)
            
            # è®¡ç®—ä»£ç åº¦é‡
            metrics = self._calculate_metrics(code_content, language)
            
            # ç”Ÿæˆæ‘˜è¦å’Œåˆ†æ
            summary = self._generate_summary(structure, metrics, language)
            analysis = self._generate_analysis(structure, metrics, language)
            
            return CodeAnalysisResult(
                language=language.title(),
                file_name=os.path.basename(file_path),
                content=code_content,
                structure=structure,
                metrics=metrics,
                summary=summary,
                analysis=analysis,
                success=True
            )
            
        except Exception as e:
            print(f"âŒ ä»£ç åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return CodeAnalysisResult(
                language="Unknown",
                file_name=os.path.basename(file_path),
                content="",
                structure={},
                metrics={},
                summary="",
                analysis="",
                success=False,
                error=str(e)
            )
    
    def _extract_structure(self, code: str, language: str) -> Dict[str, Any]:
        """æå–ä»£ç ç»“æ„"""
        structure = {
            "classes": [],
            "functions": [],
            "imports": []
        }
        
        patterns = self.language_patterns.get(language, {})
        
        # æå–ç±»
        if "class_pattern" in patterns:
            classes = re.findall(patterns["class_pattern"], code)
            structure["classes"] = [{"name": cls} for cls in classes if cls]
        
        # æå–å‡½æ•°/æ–¹æ³•
        if "function_pattern" in patterns:
            functions = re.findall(patterns["function_pattern"], code)
            # å¤„ç†å…ƒç»„ç»“æœ
            if functions and isinstance(functions[0], tuple):
                functions = [f for group in functions for f in group if f]
            structure["functions"] = [{"name": func} for func in functions if func]
        elif "method_pattern" in patterns:
            methods = re.findall(patterns["method_pattern"], code)
            structure["functions"] = [{"name": m[1] if isinstance(m, tuple) else m} for m in methods]
        
        # æå–å¯¼å…¥/åŒ…å«
        if "import_pattern" in patterns:
            imports = re.findall(patterns["import_pattern"], code)
            structure["imports"] = [{"name": imp} for imp in imports]
        elif "include_pattern" in patterns:
            includes = re.findall(patterns["include_pattern"], code)
            structure["imports"] = [{"name": inc} for inc in includes]
        
        return structure
    
    def _calculate_metrics(self, code: str, language: str) -> Dict[str, Any]:
        """è®¡ç®—ä»£ç åº¦é‡"""
        lines = code.split('\n')
        
        # æ ¹æ®è¯­è¨€ç¡®å®šæ³¨é‡Šç¬¦å·
        comment_patterns = {
            "java": r'^\s*//',
            "javascript": r'^\s*//',
            "cpp": r'^\s*//',
            "c": r'^\s*//',
            "go": r'^\s*//',
            "rust": r'^\s*//'
        }
        
        comment_pattern = comment_patterns.get(language, r'^\s*//')
        
        metrics = {
            "total_lines": len(lines),
            "code_lines": len([line for line in lines if line.strip() and not re.match(comment_pattern, line)]),
            "comment_lines": len([line for line in lines if re.match(comment_pattern, line)]),
            "blank_lines": len([line for line in lines if not line.strip()])
        }
        
        # ç»Ÿè®¡æ§åˆ¶ç»“æ„
        metrics["if_count"] = len(re.findall(r'\bif\s*\(', code))
        metrics["for_count"] = len(re.findall(r'\bfor\s*\(', code))
        metrics["while_count"] = len(re.findall(r'\bwhile\s*\(', code))
        
        metrics["complexity_score"] = metrics["if_count"] + metrics["for_count"] + metrics["while_count"]
        
        return metrics
    
    def _generate_summary(self, structure: Dict, metrics: Dict, language: str) -> str:
        """ç”Ÿæˆä»£ç æ‘˜è¦"""
        summary_parts = []
        
        summary_parts.append(f"ğŸ“Š ä»£ç è¡Œæ•°: {metrics['total_lines']} è¡Œ")
        summary_parts.append(f"  - æœ‰æ•ˆä»£ç : {metrics['code_lines']} è¡Œ")
        summary_parts.append(f"  - æ³¨é‡Š: {metrics['comment_lines']} è¡Œ")
        
        if structure["imports"]:
            summary_parts.append(f"ğŸ“¦ å¯¼å…¥/åŒ…å«: {len(structure['imports'])} ä¸ª")
        
        if structure["classes"]:
            summary_parts.append(f"ğŸ—ï¸ ç±»å®šä¹‰: {len(structure['classes'])} ä¸ª")
        
        if structure["functions"]:
            summary_parts.append(f"âš™ï¸ å‡½æ•°/æ–¹æ³•: {len(structure['functions'])} ä¸ª")
        
        if metrics.get("complexity_score", 0) > 0:
            summary_parts.append(f"ğŸ“ˆ æ§åˆ¶ç»“æ„: if({metrics.get('if_count', 0)}) for({metrics.get('for_count', 0)}) while({metrics.get('while_count', 0)})")
        
        return "\n".join(summary_parts)
    
    def _generate_analysis(self, structure: Dict, metrics: Dict, language: str) -> str:
        """ç”Ÿæˆä»£ç åˆ†æ"""
        analysis_parts = []
        
        if structure["classes"]:
            analysis_parts.append(f"ğŸ—ï¸ ä½¿ç”¨{language.upper()}é¢å‘å¯¹è±¡ç¼–ç¨‹")
        
        if structure["functions"]:
            func_count = len(structure["functions"])
            if func_count > 20:
                analysis_parts.append(f"âš™ï¸ å‡½æ•°è¾ƒå¤š ({func_count}ä¸ª)ï¼Œå»ºè®®è€ƒè™‘æ¨¡å—åŒ–")
            else:
                analysis_parts.append(f"âš™ï¸ å‡½æ•°ç»“æ„æ¸…æ™° ({func_count}ä¸ª)")
        
        # æ³¨é‡Šç‡åˆ†æ
        if metrics["code_lines"] > 0:
            comment_ratio = metrics["comment_lines"] / metrics["code_lines"] * 100
            if comment_ratio > 20:
                analysis_parts.append(f"ğŸ“ æ³¨é‡Šå……åˆ† ({comment_ratio:.1f}%)")
            elif comment_ratio > 10:
                analysis_parts.append(f"ğŸ“ æ³¨é‡Šé€‚ä¸­ ({comment_ratio:.1f}%)")
            else:
                analysis_parts.append(f"ğŸ“ æ³¨é‡Šè¾ƒå°‘ ({comment_ratio:.1f}%)ï¼Œå»ºè®®å¢åŠ æ–‡æ¡£")
        
        return "\n".join(analysis_parts) if analysis_parts else f"ğŸ“„ æ ‡å‡†{language.upper()}ä»£ç "

# æµ‹è¯•å‡½æ•°
def test_code_analyzer():
    """æµ‹è¯•ä»£ç åˆ†æå™¨"""
    print("[TEST] æµ‹è¯•ä»£ç åˆ†æå™¨...")
    
    # æµ‹è¯•Pythonåˆ†æå™¨
    py_analyzer = PythonCodeAnalyzer()
    print(f"\n{py_analyzer.name} å·²åˆ›å»º")
    
    # æµ‹è¯•é€šç”¨åˆ†æå™¨
    general_analyzer = GeneralCodeAnalyzer()
    print(f"{general_analyzer.name} å·²åˆ›å»º")
    
    print("\n[OK] ä»£ç åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸï¼")

if __name__ == "__main__":
    test_code_analyzer()

